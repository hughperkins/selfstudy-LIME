{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME\n",
    "\n",
    "LIME is 'locally interpetable model-agnostic explanations'.\n",
    "\n",
    "The paper is at http://arxiv.org/pdf/1602.04938v1.pdf , by Ribeiro, Singh, and Guestrin.  Ribeiro has a blog post about it at https://homes.cs.washington.edu/~marcotcr/blog/lime/ . There is code provided by Ribeiro at https://github.com/marcotcr/lime\n",
    "\n",
    "There is thus already ample documentation and code about LIME, and this repo is for self-study purposes primarily, and likely wont introduce anything much new to the world, for now :-)\n",
    "\n",
    "## What LIME does\n",
    "\n",
    "LIME does the following:\n",
    "- creates interpretable features, which for sparse nlp models means, they draw the first few features from a LARS path, and use those.  self-study notebook for LARS: https://github.com/hughperkins/selfstudy-LARS/blob/master/test_lars.ipynb\n",
    "- samples from interpretable feature space, near an example we wish to explain\n",
    "- uses local gradients, from near the target example, to explain which interpretable features most affect decisions around that example\n",
    "\n",
    "## LIME Experiments\n",
    "\n",
    "### Train and test distributions differ\n",
    "\n",
    "- train on news20, for atheist vs christianity\n",
    "- test against new [religion](https://github.com/marcotcr/lime-experiments/blob/master/religion_dataset.tar.gz) dataset, created from websites from from [DMOZ](https://github.com/marcotcr/lime-experiments/blob/master/religion_dataset.tar.gz) directory\n",
    "  - these data points have similar classes to the news20 training sets, ie atheism vs christianity.  However, the features are fairly different, and eg learning the names of prolific atheist posters in news20 wont generalize to the DMOZ websites.\n",
    "- the idea is to examine to what extent the LIME explanations (or any other explanations for that matter) can facilitate rmeoving 'junk' features, after/during training, and thus improving the score on the DMOZ-derived dataset\n",
    "\n",
    "Let's start by downloading the datasets, and training a simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import tarfile\n",
    "import sklearn.datasets\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "import argparse\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "from os.path import join\n",
    "import urllib.request\n",
    "import hashlib\n",
    "\n",
    "\n",
    "global_categories = ['atheism', 'religion']\n",
    "news_categories = ['alt.atheism', 'soc.religion.christian']\n",
    "\n",
    "religion_url = 'https://github.com/marcotcr/lime-experiments/blob/master/religion_dataset.tar.gz?raw=true'\n",
    "\n",
    "\n",
    "def get_md5(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        dat = f.read()\n",
    "    return hashlib.md5(dat).hexdigest()\n",
    "\n",
    "\n",
    "def download_religion():\n",
    "    file_exists = False\n",
    "    home_dir = os.environ['HOME']\n",
    "    limedata_dir = join(home_dir, 'limedata')\n",
    "    if not path.isdir(limedata_dir):\n",
    "        os.makedirs(limedata_dir)\n",
    "    religion_filepath = join(limedata_dir, 'religion_dataset.tar.gz')\n",
    "    if path.isfile(religion_filepath):\n",
    "        md5sum = get_md5(religion_filepath)\n",
    "        if md5sum == '0f12beb283869a09584493ddf93672b6':\n",
    "            file_exists = True\n",
    "    if not file_exists:\n",
    "        print('downloading religion dataset...')\n",
    "        with urllib.request.urlopen(religion_url) as response, open(religion_filepath, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)\n",
    "            print(get_md5(religion_filepath))\n",
    "            print('... downloaded religion dataset')\n",
    "    return religion_filepath\n",
    "\n",
    "\n",
    "def fetch_religion():\n",
    "    tar_filepath = download_religion()\n",
    "    # res = sklearn.datasets.base.Bunch()\n",
    "    examples = []\n",
    "    print('loading religion dataset to memory...')\n",
    "    tar = tarfile.open(tar_filepath)\n",
    "    # print(tar.getmembers())\n",
    "    class_name_by_id = ['atheism', 'christianity']\n",
    "    class_id_by_name = {name: id for id, name in enumerate(class_name_by_id)}\n",
    "    print('class_id_by_name', class_id_by_name)\n",
    "    N_per_class = 819\n",
    "    y = np.zeros((N_per_class * 2), dtype=np.int64)\n",
    "    n = 0\n",
    "    count_per_class = defaultdict(int)\n",
    "    for m in tar.getmembers():\n",
    "        # print(m)\n",
    "        # print(dir(m))\n",
    "        # print(m.name, m.path, m.type)\n",
    "        if '/' in m.path:\n",
    "            class_name = m.path.split('/')[0]\n",
    "            class_id = class_id_by_name[class_name]\n",
    "            if count_per_class[class_id] >= N_per_class:\n",
    "                continue\n",
    "            # if m.path not in ['README.txt', 'atheism', 'christianity']:\n",
    "            f = tar.extractfile(m)\n",
    "            try:\n",
    "                content = f.read()\n",
    "                content = content.decode('utf-8')\n",
    "            except:\n",
    "                # raise Exception('failed for [%s]' % content)\n",
    "                print('failed to decode to utf-8 => skipping 1 doc')\n",
    "                continue\n",
    "            finally:\n",
    "                f.close()\n",
    "            examples.append(content)\n",
    "            y[n] = class_id\n",
    "            count_per_class[class_id] += 1\n",
    "            n += 1\n",
    "    tar.close()\n",
    "    print('... religion dataset loaded')\n",
    "    return sklearn.datasets.base.Bunch(data=examples, target=y)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, trainer):\n",
    "        self.trainer = trainer\n",
    "        trainers = {\n",
    "            'nb': MultinomialNB(),\n",
    "            'sgd': SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                 alpha=1e-3, n_iter=5, random_state=123),\n",
    "            'rbf': SVC(C=1000000, kernel='rbf')\n",
    "        }\n",
    "        self.model = trainers[trainer]\n",
    "        print('trainer: %s' % trainer)\n",
    "\n",
    "    def train(self):\n",
    "        self.twenty_train = fetch_20newsgroups(subset='train', categories=news_categories, shuffle=True, random_state=123)\n",
    "        self.count_vect = CountVectorizer()\n",
    "        X_train_counts = self.count_vect.fit_transform(self.twenty_train.data)\n",
    "\n",
    "        self.tfidf_transformer = TfidfTransformer()\n",
    "        X_train_tfidf = self.tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "        # model = MultinomialNB()\n",
    "        self.model.fit(X_train_tfidf, self.twenty_train.target)\n",
    "        train_pred = self.model.predict(X_train_tfidf)\n",
    "        train_num_right = np.equal(train_pred, self.twenty_train.target).sum()\n",
    "        print('train', train_num_right, train_num_right / len(self.twenty_train.target) * 100)\n",
    "        # return model\n",
    "\n",
    "    def test(self):\n",
    "        self.twenty_test = fetch_20newsgroups(subset='test', categories=news_categories, shuffle=True, random_state=123)\n",
    "        X_test_counts = self.count_vect.transform(self.twenty_test.data)\n",
    "\n",
    "        X_test_tfidf = self.tfidf_transformer.transform(X_test_counts)\n",
    "        test_pred = self.model.predict(X_test_tfidf)\n",
    "        test_num_right = np.equal(test_pred, self.twenty_test.target).sum()\n",
    "        print('test', test_num_right, test_num_right / len(self.twenty_test.target) * 100)\n",
    "\n",
    "        # now try religion dataset, from https://github.com/marcotcr/lime-experiments/blob/master/religion_dataset.tar.gz\n",
    "        religion_test = fetch_religion()\n",
    "        religion_X_test_counts = self.count_vect.transform(religion_test.data)\n",
    "        religion_X_test_tfidf = self.tfidf_transformer.transform(religion_X_test_counts)\n",
    "        religion_test_pred = self.model.predict(religion_X_test_tfidf)\n",
    "        religion_test_num_right = np.equal(religion_test_pred, religion_test.target).sum()\n",
    "        print('religion test', religion_test_num_right, religion_test_num_right / len(religion_test.target) * 100)\n",
    "\n",
    "model = Model('sgd')\n",
    "model.train()\n",
    "model.test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
